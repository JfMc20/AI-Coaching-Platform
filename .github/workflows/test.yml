name: Test Suite

on:
  push:
    branches: [ main, develop ]
  pull_request:
    branches: [ main, develop ]
  schedule:
    # Run tests daily at 2 AM UTC
    - cron: '0 2 * * *'

env:
  PYTHON_VERSION: '3.11'
  NODE_VERSION: '18'

jobs:
  # Code quality checks
  quality:
    name: Code Quality
    runs-on: ubuntu-latest
    
    steps:
    - name: Checkout code
      uses: actions/checkout@v4
      
    - name: Set up Python
      uses: actions/setup-python@v4
      with:
        python-version: ${{ env.PYTHON_VERSION }}
        
    - name: Cache pip dependencies
      uses: actions/cache@v3
      with:
        path: ~/.cache/pip
        key: ${{ runner.os }}-pip-${{ hashFiles('**/requirements*.txt') }}
        restore-keys: |
          ${{ runner.os }}-pip-
          
    - name: Install dependencies
      run: |
        python -m pip install --upgrade pip
        pip install -r requirements.txt
        pip install -r requirements-test.txt
        
    - name: Run linting (flake8)
      run: |
        flake8 --config=.flake8 services/ shared/ tests/
        
    - name: Run formatting check (black)
      run: |
        black --check --diff services/ shared/ tests/
        
    - name: Run import sorting check (isort)
      run: |
        isort --check-only --diff services/ shared/ tests/
        
    - name: Run type checking (mypy)
      run: |
        mypy services/ shared/
        
    - name: Run security check (bandit)
      run: |
        bandit -r services/ shared/ -f json -o bandit-report.json
        
    - name: Run dependency security check (safety)
      run: |
        safety check --json --output safety-report.json
        
    - name: Upload security reports
      uses: actions/upload-artifact@v3
      if: success() || failure()
      with:
        name: security-reports
        path: |
          bandit-report.json
          safety-report.json

  # Dead code analysis
  dead-code:
    name: Dead Code Analysis
    runs-on: ubuntu-latest
    
    steps:
    - name: Checkout code
      uses: actions/checkout@v4
      
    - name: Set up Python
      uses: actions/setup-python@v4
      with:
        python-version: ${{ env.PYTHON_VERSION }}
        
    - name: Install dependencies
      run: |
        python -m pip install --upgrade pip
        pip install -r requirements.txt
        
    - name: Run dead code analysis
      run: |
        python scripts/dead_code_analysis.py --check-only
        
    - name: Run hardcoded values analysis
      run: |
        python scripts/hardcoded_values_analysis.py --check-only --critical-only
        
    - name: Run environment cleanup check
      run: |
        python scripts/env_cleanup.py --dry-run

  # Unit tests
  unit-tests:
    name: Unit Tests
    runs-on: ubuntu-latest
    strategy:
      matrix:
        python-version: ['3.11', '3.12']
        
    steps:
    - name: Checkout code
      uses: actions/checkout@v4
      
    - name: Set up Python ${{ matrix.python-version }}
      uses: actions/setup-python@v4
      with:
        python-version: ${{ matrix.python-version }}
        
    - name: Cache pip dependencies
      uses: actions/cache@v3
      with:
        path: ~/.cache/pip
        key: ${{ runner.os }}-${{ matrix.python-version }}-pip-${{ hashFiles('**/requirements*.txt') }}
        restore-keys: |
          ${{ runner.os }}-${{ matrix.python-version }}-pip-
          
    - name: Install dependencies
      run: |
        python -m pip install --upgrade pip
        pip install -r requirements.txt
        pip install -r requirements-test.txt
        
    - name: Run unit tests
      run: |
        pytest -m unit --cov=shared --cov=services \
               --cov-report=xml --cov-report=html \
               --junit-xml=junit-unit.xml \
               --html=unit-report.html --self-contained-html
               
    - name: Upload unit test results
      uses: actions/upload-artifact@v3
      if: success() || failure()
      with:
        name: unit-test-results-${{ matrix.python-version }}
        path: |
          junit-unit.xml
          unit-report.html
          htmlcov/
          
    - name: Upload coverage to Codecov
      uses: codecov/codecov-action@v3
      with:
        file: ./coverage.xml
        flags: unit
        name: unit-tests-${{ matrix.python-version }}

  # Integration tests
  integration-tests:
    name: Integration Tests
    runs-on: ubuntu-latest
    
    services:
      postgres:
        image: postgres:15
        env:
          POSTGRES_DB: ai_platform_test
          POSTGRES_USER: postgres
          POSTGRES_PASSWORD: ${{ secrets.TEST_POSTGRES_PASSWORD }}
        options: >-
          --health-cmd pg_isready
          --health-interval 10s
          --health-timeout 5s
          --health-retries 5
        ports:
          - 5433:5432
          
      redis:
        image: redis:7
        options: >-
          --health-cmd "redis-cli ping"
          --health-interval 10s
          --health-timeout 5s
          --health-retries 5
        ports:
          - 6380:6379
    
    steps:
    - name: Checkout code
      uses: actions/checkout@v4
      
    - name: Set up Python
      uses: actions/setup-python@v4
      with:
        python-version: ${{ env.PYTHON_VERSION }}
        
    - name: Cache pip dependencies
      uses: actions/cache@v3
      with:
        path: ~/.cache/pip
        key: ${{ runner.os }}-pip-${{ hashFiles('**/requirements*.txt') }}
        restore-keys: |
          ${{ runner.os }}-pip-
          
    - name: Install dependencies
      run: |
        python -m pip install --upgrade pip
        pip install -r requirements.txt
        pip install -r requirements-test.txt
        
    - name: Set up test environment
      run: |
        export DATABASE_URL=postgresql://postgres:${{ secrets.TEST_POSTGRES_PASSWORD }}@localhost:5433/ai_platform_test
        export REDIS_URL=redis://localhost:6380/0
        export ENVIRONMENT=testing
        
    - name: Run database migrations
      run: |
        alembic upgrade head
      env:
        DATABASE_URL: postgresql://postgres:${{ secrets.TEST_POSTGRES_PASSWORD }}@localhost:5433/ai_platform_test
        REDIS_URL: redis://localhost:6380/0
        ENVIRONMENT: testing
        JWT_SECRET_KEY: ${{ secrets.TEST_JWT_SECRET_KEY }}
        
    - name: Run integration tests
      run: |
        pytest -m integration --cov=shared --cov=services \
               --cov-report=xml --cov-report=html \
               --junit-xml=junit-integration.xml \
               --html=integration-report.html --self-contained-html
      env:
        DATABASE_URL: postgresql://postgres:${{ secrets.TEST_POSTGRES_PASSWORD }}@localhost:5433/ai_platform_test
        REDIS_URL: redis://localhost:6380/0
        ENVIRONMENT: testing
        
    - name: Upload integration test results
      uses: actions/upload-artifact@v3
      if: success() || failure()
      with:
        name: integration-test-results
        path: |
          junit-integration.xml
          integration-report.html
          htmlcov/
          
    - name: Upload coverage to Codecov
      uses: codecov/codecov-action@v3
      with:
        file: ./coverage.xml
        flags: integration
        name: integration-tests

  # End-to-end tests with full Docker environment
  e2e-tests:
    name: End-to-End Tests
    runs-on: ubuntu-latest
    
    steps:
    - name: Checkout code
      uses: actions/checkout@v4
      
    - name: Set up Docker Buildx
      uses: docker/setup-buildx-action@v3
      
    - name: Cache Docker layers
      uses: actions/cache@v3
      with:
        path: /tmp/.buildx-cache
        key: ${{ runner.os }}-buildx-${{ github.sha }}
        restore-keys: |
          ${{ runner.os }}-buildx-
          
    - name: Start test environment
      run: |
        docker-compose -f docker-compose.test.yml up -d --build
        
    - name: Wait for services to be ready
      run: |
        timeout 300 bash -c 'until docker-compose -f docker-compose.test.yml exec -T postgres-test pg_isready -U postgres; do sleep 5; done'
        timeout 300 bash -c 'until docker-compose -f docker-compose.test.yml exec -T redis-test redis-cli ping; do sleep 5; done'
        
    - name: Run database migrations
      run: |
        docker-compose -f docker-compose.test.yml exec -T auth-service-test alembic upgrade head
        
    - name: Create test results directory
      run: |
        mkdir -p test-results
        
    - name: Run end-to-end tests
      run: |
        docker-compose -f docker-compose.test.yml run --rm \
          -v $(pwd)/test-results:/app/test-results \
          test-runner \
          pytest -m e2e --junit-xml=/app/test-results/junit-e2e.xml \
          --html=/app/test-results/e2e-report.html --self-contained-html
        
    - name: Upload e2e test results
      uses: actions/upload-artifact@v3
      if: success() || failure()
      with:
        name: e2e-test-results
        path: test-results/
          
    - name: Collect service logs
      if: failure()
      run: |
        mkdir -p logs
        docker-compose -f docker-compose.test.yml logs auth-service-test > logs/auth-service.log
        docker-compose -f docker-compose.test.yml logs ai-engine-service-test > logs/ai-engine.log
        docker-compose -f docker-compose.test.yml logs creator-hub-service-test > logs/creator-hub.log
        docker-compose -f docker-compose.test.yml logs channel-service-test > logs/channel.log
        
    - name: Upload service logs
      uses: actions/upload-artifact@v3
      if: failure()
      with:
        name: service-logs
        path: logs/
        
    - name: Cleanup test environment
      if: always()
      run: |
        docker-compose -f docker-compose.test.yml down -v

  # Performance tests
  performance-tests:
    name: Performance Tests
    runs-on: ubuntu-latest
    if: github.event_name == 'schedule' || (github.event_name == 'pull_request' && contains(github.event.pull_request.labels.*.name, 'performance'))
    
    steps:
    - name: Checkout code
      uses: actions/checkout@v4
      
    - name: Set up Python
      uses: actions/setup-python@v4
      with:
        python-version: ${{ env.PYTHON_VERSION }}
        
    - name: Install dependencies
      run: |
        python -m pip install --upgrade pip
        pip install -r requirements.txt
        pip install -r requirements-test.txt
        
    - name: Start test services
      run: |
        docker-compose -f docker-compose.test.yml up -d postgres-test redis-test
        
    - name: Run performance tests
      run: |
        pytest -m performance --benchmark-json=benchmark.json \
               --junit-xml=junit-performance.xml
               
    - name: Upload performance results
      uses: actions/upload-artifact@v3
      if: success() || failure()
      with:
        name: performance-results
        path: |
          benchmark.json
          junit-performance.xml

  # Security tests
  security-tests:
    name: Security Tests
    runs-on: ubuntu-latest
    
    steps:
    - name: Checkout code
      uses: actions/checkout@v4
      
    - name: Set up Python
      uses: actions/setup-python@v4
      with:
        python-version: ${{ env.PYTHON_VERSION }}
        
    - name: Install dependencies
      run: |
        python -m pip install --upgrade pip
        pip install -r requirements.txt
        pip install -r requirements-test.txt
        
    - name: Run security tests
      run: |
        pytest -m security --junit-xml=junit-security.xml \
               --html=security-report.html --self-contained-html
               
    - name: Upload security test results
      uses: actions/upload-artifact@v3
      if: success() || failure()
      with:
        name: security-test-results
        path: |
          junit-security.xml
          security-report.html

  # Test summary and reporting
  test-summary:
    name: Test Summary
    runs-on: ubuntu-latest
    needs: [quality, dead-code, unit-tests, integration-tests, e2e-tests]
    if: always()
    
    steps:
    - name: Download all test artifacts
      uses: actions/download-artifact@v3
      
    - name: Generate test summary
      run: |
        echo "# Test Summary" > test-summary.md
        echo "" >> test-summary.md
        echo "## Test Results" >> test-summary.md
        echo "" >> test-summary.md
        
        # Check job results
        if [ "${{ needs.quality.result }}" == "success" ]; then
          echo "✅ Code Quality: PASSED" >> test-summary.md
        else
          echo "❌ Code Quality: FAILED" >> test-summary.md
        fi
        
        if [ "${{ needs.dead-code.result }}" == "success" ]; then
          echo "✅ Dead Code Analysis: PASSED" >> test-summary.md
        else
          echo "❌ Dead Code Analysis: FAILED" >> test-summary.md
        fi
        
        if [ "${{ needs.unit-tests.result }}" == "success" ]; then
          echo "✅ Unit Tests: PASSED" >> test-summary.md
        else
          echo "❌ Unit Tests: FAILED" >> test-summary.md
        fi
        
        if [ "${{ needs.integration-tests.result }}" == "success" ]; then
          echo "✅ Integration Tests: PASSED" >> test-summary.md
        else
          echo "❌ Integration Tests: FAILED" >> test-summary.md
        fi
        
        if [ "${{ needs.e2e-tests.result }}" == "success" ]; then
          echo "✅ End-to-End Tests: PASSED" >> test-summary.md
        else
          echo "❌ End-to-End Tests: FAILED" >> test-summary.md
        fi
        
        echo "" >> test-summary.md
        echo "## Artifacts" >> test-summary.md
        echo "" >> test-summary.md
        echo "- Test reports and coverage data are available in the artifacts section" >> test-summary.md
        echo "- Security reports include bandit and safety scan results" >> test-summary.md
        echo "- Service logs are available if any tests failed" >> test-summary.md
        
    - name: Upload test summary
      uses: actions/upload-artifact@v3
      with:
        name: test-summary
        path: test-summary.md
        
    - name: Comment PR with test results
      if: github.event_name == 'pull_request'
      uses: actions/github-script@v6
      with:
        script: |
          const fs = require('fs');
          const summary = fs.readFileSync('test-summary.md', 'utf8');
          
          github.rest.issues.createComment({
            issue_number: context.issue.number,
            owner: context.repo.owner,
            repo: context.repo.repo,
            body: summary
          });

  # Cleanup
  cleanup:
    name: Cleanup
    runs-on: ubuntu-latest
    permissions:
      actions: write
    needs: [test-summary]
    if: always()
    
    steps:
    - name: Cleanup old artifacts
      uses: actions/github-script@v6
      with:
        script: |
          // Get all artifacts for the repository
          const artifacts = await github.rest.actions.listArtifactsForRepo({
            owner: context.repo.owner,
            repo: context.repo.repo,
            per_page: 100
          });
          
          // Group artifacts by normalized name (remove matrix suffixes, timestamps, etc.)
          const artifactGroups = {};
          artifacts.data.artifacts.forEach(artifact => {
            // Validate artifact properties
            if (!artifact.id || !artifact.name || !artifact.created_at) {
              console.log(`⚠️  Skipping invalid artifact: missing required properties (id: ${artifact.id}, name: ${artifact.name}, created_at: ${artifact.created_at})`);
              return;
            }
            
            // Validate created_at is a valid date
            const createdDate = new Date(artifact.created_at);
            if (isNaN(createdDate.getTime())) {
              console.log(`⚠️  Skipping artifact ${artifact.name}: invalid created_at date (${artifact.created_at})`);
              return;
            }
            
            // Normalize artifact name by removing common suffixes
            let baseName = artifact.name
              .replace(/-\d+\.\d+$/, '')  // Remove version numbers
              .replace(/-\d{4}-\d{2}-\d{2}.*$/, '')  // Remove timestamps
              .replace(/-python-\d+\.\d+$/, '')  // Remove python version matrix
              .replace(/-ubuntu-latest$/, '')  // Remove runner info
              .replace(/-\w+-\d+$/, '');  // Remove other matrix variations
            
            if (!artifactGroups[baseName]) {
              artifactGroups[baseName] = [];
            }
            artifactGroups[baseName].push(artifact);
          });
          
          // Keep only the latest 10 artifacts per group
          for (const [groupName, groupArtifacts] of Object.entries(artifactGroups)) {
            if (groupArtifacts.length > 10) {
              const toDelete = groupArtifacts
                .sort((a, b) => new Date(b.created_at) - new Date(a.created_at))
                .slice(10);
              
              console.log(`Cleaning up ${toDelete.length} old artifacts for group: ${groupName}`);
              
              for (const artifact of toDelete) {
                // Additional validation before deletion
                if (!artifact.id || typeof artifact.id !== 'number') {
                  console.log(`⚠️  Skipping deletion of artifact ${artifact.name}: invalid ID (${artifact.id})`);
                  continue;
                }
                
                try {
                  await github.rest.actions.deleteArtifact({
                    owner: context.repo.owner,
                    repo: context.repo.repo,
                    artifact_id: artifact.id,
                  });
                  console.log(`✅ Deleted artifact: ${artifact.name} (${artifact.id})`);
                } catch (error) {
                  console.log(`❌ Failed to delete artifact ${artifact.name} (${artifact.id}): ${error.message}`);
                }
              }
            }
          }